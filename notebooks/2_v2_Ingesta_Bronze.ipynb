{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOP3ifgG2Oiu874vHASHbGL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Notebook 2** (v2)\n","\n","Ingesta automatizada y creaci√≥n de Bronze Layer"],"metadata":{"id":"e_q2BIPUDWsG"}},{"cell_type":"markdown","source":["Objetivos del presente notebook:\n","- Automatizar la descarga de datos\n","- Estandarizar el proceso de ingesta\n","- Validaci√≥n inicial robusta"],"metadata":{"id":"EOrGqycgCjbo"}},{"cell_type":"markdown","source":["Versiones:\n","- v2: limpieza de v1; acabado"],"metadata":{"id":"4483-tn3D1mZ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"bl2C3MEmCQ14","executionInfo":{"status":"ok","timestamp":1762681006371,"user_tz":-60,"elapsed":28,"user":{"displayName":"Enrique Mej√≠a","userId":"14106173949036430943"}}},"outputs":[],"source":[]},{"cell_type":"markdown","source":["**Librer√≠as**"],"metadata":{"id":"2GfmPzQoD5Bk"}},{"cell_type":"code","source":["import pandas as pd\n","\n","from pyspark.sql import SparkSession, DataFrame\n","\n","#from pyspark.sql.functions import * -> no usar para evitar problemas de compatibilidad Python-Spark\n","from pyspark.sql.functions import (\n","    sum as spark_sum,\n","    min as spark_min,\n","    max as spark_max,\n","    col, when, current_timestamp, lit\n",")\n","\n","from pyspark.sql.types import *\n","from pyspark.sql import functions as F\n","\n","from datetime import datetime, timedelta\n","from typing import List, Dict, Optional, Any\n","\n","import requests\n","\n","from urllib.parse import urlparse\n","from google.colab import drive\n","\n","import os\n","import json\n","import hashlib"],"metadata":{"id":"WVR2M89WD1kq","executionInfo":{"status":"ok","timestamp":1762681010178,"user_tz":-60,"elapsed":3805,"user":{"displayName":"Enrique Mej√≠a","userId":"14106173949036430943"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"qDV47ZEeD3O2","executionInfo":{"status":"ok","timestamp":1762681010191,"user_tz":-60,"elapsed":11,"user":{"displayName":"Enrique Mej√≠a","userId":"14106173949036430943"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["**Google Drive**"],"metadata":{"id":"h0If6qVoEBgR"}},{"cell_type":"code","source":["# monta Google Drive\n","if not os.path.exists('/content/drive'):\n","    drive.mount('/content/drive')"],"metadata":{"id":"tVWl5DdPOyys","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762681026488,"user_tz":-60,"elapsed":16296,"user":{"displayName":"Enrique Mej√≠a","userId":"14106173949036430943"}},"outputId":"2e97ee5c-eb2f-4df4-9230-b17b0844feff"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# crea la estructura de directorios\n","\n","# configuraci√≥n de paths\n","PROJECT_ROOT = \"/content/drive/MyDrive/taxi_project\"\n","RAW_DIR = f\"{PROJECT_ROOT}/raw\"\n","BRONZE_DIR = f\"{PROJECT_ROOT}/bronze\"\n","METADATA_DIR = f\"{PROJECT_ROOT}/metadata\"\n","\n","# ruta donde guardar la capa Bronze\n","BRONZE_PATH = f\"{BRONZE_DIR}/taxi_data\"\n","\n","# crea directorios si no existen\n","for path in [RAW_DIR, BRONZE_DIR, METADATA_DIR]:\n","    os.makedirs(path, exist_ok=True)"],"metadata":{"id":"90_kAii9PGKG","executionInfo":{"status":"ok","timestamp":1762681026835,"user_tz":-60,"elapsed":346,"user":{"displayName":"Enrique Mej√≠a","userId":"14106173949036430943"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"eaTJz4tR_Ijg","executionInfo":{"status":"ok","timestamp":1762681026856,"user_tz":-60,"elapsed":19,"user":{"displayName":"Enrique Mej√≠a","userId":"14106173949036430943"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["**Diagrama de carpetas y archivos**\n","\n","Sigue la estructura de particiones de Hive.\n","\n","/content/drive/MyDrive/taxi_project/<br>\n","‚îú‚îÄ‚îÄ raw/ ## archivos originales descargados<br>\n","‚îÇ   ‚îú‚îÄ‚îÄ yellow_tripdata_2023-01.parquet<br>\n","‚îÇ   ‚îú‚îÄ‚îÄ yellow_tripdata_2023-02.parquet<br>\n","‚îÇ   ‚îî‚îÄ‚îÄ yellow_tripdata_2023-03.parquet<br>\n","‚îÇ<br>\n","‚îú‚îÄ‚îÄ bronze/ ## datasets validados en formato Parquet<br>\n","‚îÇ   ‚îî‚îÄ‚îÄ taxi_data/<br>\n","‚îÇ       ‚îú‚îÄ‚îÄ ingestion_year=2023/<br>\n","‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ ingestion_month=01/<br>\n","‚îÇ       ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ part-*.snappy.parquet<br>\n","‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ ingestion_month=02/<br>\n","‚îÇ       ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ part-*.snappy.parquet<br>\n","‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ ingestion_month=03/<br>\n","‚îÇ       ‚îÇ       ‚îî‚îÄ‚îÄ part-*.snappy.parquet<br>\n","‚îÇ<br>\n","‚îú‚îÄ‚îÄ metadata/ ## almac√©n de logs y metadatos de ingesta<br>\n","‚îÇ   ‚îú‚îÄ‚îÄ ingestion_log.jsonl ## logs de eventos de ingesta<br>\n","‚îÇ   ‚îî‚îÄ‚îÄ bronze_layer_metadata.json ## metadatos de la capa Bronze"],"metadata":{"id":"Fh0C0-zF_JRJ"}},{"cell_type":"code","source":[],"metadata":{"id":"zRU4HbfdSuo6","executionInfo":{"status":"ok","timestamp":1762681026859,"user_tz":-60,"elapsed":1,"user":{"displayName":"Enrique Mej√≠a","userId":"14106173949036430943"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["**Configuraci√≥n de Spark**"],"metadata":{"id":"EB_y2kwcEG2G"}},{"cell_type":"code","source":["# setup para Spark en Google Colab\n","\n","# instala Java si no est√°\n","!apt-get install -y openjdk-11-jdk-headless -qq > /dev/null\n","\n","# fija JAVA_HOME\n","os.environ['JAVA_HOME'] = '/usr/lib/jvm/java-11-openjdk-amd64'\n","\n","# asegura versi√≥n compatible de PySpark\n","!pip install -q pyspark==3.5.1"],"metadata":{"id":"OdVUGB6B8K0l","executionInfo":{"status":"ok","timestamp":1762681054079,"user_tz":-60,"elapsed":27219,"user":{"displayName":"Enrique Mej√≠a","userId":"14106173949036430943"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# configuraci√≥n optimizada de Spark para Colab\n","spark = SparkSession.builder \\\n","    .appName(\"NYC-Taxi-Ingesta\") \\\n","    .config(\"spark.driver.memory\", \"4g\") \\\n","    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n","    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n","    .config(\"spark.driver.maxResultSize\", \"2g\") \\\n","    .getOrCreate()\n","\n","print(f\"‚úÖ Spark inicializado - Version: {spark.version}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ydsW4oeISGnP","executionInfo":{"status":"ok","timestamp":1762681071367,"user_tz":-60,"elapsed":17285,"user":{"displayName":"Enrique Mej√≠a","userId":"14106173949036430943"}},"outputId":"5f7a7637-9d22-4744-ca87-466295601a53"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Spark inicializado - Version: 3.5.1\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"_eFegOViO9SS","executionInfo":{"status":"ok","timestamp":1762681071377,"user_tz":-60,"elapsed":14,"user":{"displayName":"Enrique Mej√≠a","userId":"14106173949036430943"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["**Funciones y clases auxiliares**"],"metadata":{"id":"Gt2TtFQvo1x2"}},{"cell_type":"code","source":[],"metadata":{"id":"QNQd92T6oddY","executionInfo":{"status":"ok","timestamp":1762681071378,"user_tz":-60,"elapsed":13,"user":{"displayName":"Enrique Mej√≠a","userId":"14106173949036430943"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def generate_file_hash(file_path: str) -> str:\n","    \"\"\"\n","    Genera el hash MD5 del contenido de un archivo para verificar su integridad,\n","    asegurando que no haya sido corrompido o modificado.\n","    Hash MD5: 128 bits (32 caracteres hexadecimales)\n","\n","    Args:\n","        file_path (str): Ruta al archivo\n","\n","    Returns:\n","        str: Hash MD5 del archivo (en formato hexadecimal) o cadena vac√≠a en caso de error\n","    \"\"\"\n","    # crea objeto hash MD5\n","    hash_md5 = hashlib.md5()\n","\n","    try:\n","        # abre archivo en modo binario\n","        with open(file_path, \"rb\") as f:\n","            # lee bloques de 4096 bytes, se detiene cuando f.read() devuele b\"\" (fin de archivo)\n","            for chunk in iter(lambda: f.read(4096), b\"\"):\n","                # actualiza el hash con cada bloque le√≠do\n","                hash_md5.update(chunk)\n","        return hash_md5.hexdigest()\n","    except Exception as e:\n","        print(f\"Error generando hash para {file_path}: {e}\")\n","        return \"\""],"metadata":{"id":"BVrq4YJGD27c","executionInfo":{"status":"ok","timestamp":1762681071380,"user_tz":-60,"elapsed":5,"user":{"displayName":"Enrique Mej√≠a","userId":"14106173949036430943"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def get_file_size_mb(file_path: str) -> float:\n","    \"\"\"\n","    Obtiene el tama√±o de archivo en MB\n","\n","    Args:\n","        file_path (str): Ruta al archivo\n","\n","    Returns:\n","        float: Tama√±o del archivo en MB\n","    \"\"\"\n","    try:\n","        return os.path.getsize(file_path) / (1024 * 1024)\n","    except:\n","        return 0.0"],"metadata":{"id":"_sh2DjtGQTfk","executionInfo":{"status":"ok","timestamp":1762681071381,"user_tz":-60,"elapsed":2,"user":{"displayName":"Enrique Mej√≠a","userId":"14106173949036430943"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def log_ingestion_event(event_type: str, details: Dict):\n","    \"\"\"\n","    Registra eventos de ingesta en archivo de log\n","\n","    Args:\n","        event_type (str): Tipo de evento\n","        details (Dict): Detalles del evento\n","    \"\"\"\n","    # diccionario de fecha actual, tipo de evento recibido y detalles del evento\n","    log_entry = {\n","        \"timestamp\": datetime.now().isoformat(),\n","        \"event_type\": event_type,\n","        \"details\": details\n","    }\n","\n","    # ruta del archivo log (un JSON por l√≠nea)\n","    log_file = f\"{METADATA_DIR}/ingestion_log.jsonl\"\n","    # abre el archivo para a√±adir l√≠neas\n","    with open(log_file, \"a\") as f:\n","        # convierte diccionario a JSON, a√±ade salto de l√≠nea y lo escribe al final del archivo\n","        f.write(json.dumps(log_entry) + \"\\n\")"],"metadata":{"id":"_4tPwYnRUbgq","executionInfo":{"status":"ok","timestamp":1762681071405,"user_tz":-60,"elapsed":17,"user":{"displayName":"Enrique Mej√≠a","userId":"14106173949036430943"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["class NYCTaxiDownloadManager:\n","    \"\"\"\n","    Clase para gestionar la descarga de archivos de NYC Taxi\n","    \"\"\"\n","    def __init__(self, config: Dict):\n","        \"\"\"\n","        Inicializa el DownloadManager con configuraci√≥n\n","\n","        Args:\n","            config (Dict): Configuraci√≥n de la descarga\n","        \"\"\"\n","        # guarda la configuraci√≥n\n","        self.config = config\n","        # estad√≠sticas de descarga\n","        self.download_stats = []\n","\n","    def generate_url(self, year: int, month: int) -> str:\n","        \"\"\"\n","        Genera URL de descarga para un mes espec√≠fico\n","\n","        Args:\n","            year (int): A√±o del mes\n","            month (int): Mes del a√±o\n","\n","        Returns:\n","            str: URL de descarga\n","        \"\"\"\n","        # nombre del archivo\n","        filename = f\"{self.config['data_type']}_{year}-{month:02d}.{self.config['file_format']}\"\n","        # URL de descarga\n","        return f\"{self.config['base_url']}/{filename}\"\n","\n","    def generate_local_path(self, year: int, month: int) -> str:\n","        \"\"\"\n","        Genera path local para guardar archivo\n","\n","        Args:\n","            year (int): A√±o del archivo\n","            month (int): Mes del archivo\n","\n","        Returns:\n","            str: Path local\n","        \"\"\"\n","        # nombre del archivo\n","        filename = f\"{self.config['data_type']}_{year}-{month:02d}.{self.config['file_format']}\"\n","        # ruta local\n","        return f\"{RAW_DIR}/{filename}\"\n","\n","    def file_exists_and_valid(self, file_path: str) -> bool:\n","        \"\"\"\n","        Comprueba si archivo existe y tiene tama√±o v√°lido (al menos 10 MB)\n","\n","        Args:\n","            file_path (str): Ruta al archivo\n","\n","        Returns:\n","            bool: True si existe y tiene tama√±o v√°lido, False en caso contrario\n","        \"\"\"\n","        # comprueba si existe el archvio\n","        if not os.path.exists(file_path):\n","            return False\n","\n","        # obtiene el tama√±o del archivo\n","        size_mb = get_file_size_mb(file_path)\n","        # comprueba que tenga al menos 10 MB\n","        return size_mb >= 10.0\n","\n","    def download_file(self, year: int, month: int) -> Dict:\n","        \"\"\"\n","        Descarga un archivo espec√≠fico con reintentos\n","\n","        Args:\n","            year (int): A√±o del archivo\n","            month (int): Mes del archivo\n","\n","        Returns:\n","            Dict: Informaci√≥n de la descarga\n","        \"\"\"\n","        # URL de descarga\n","        url = self.generate_url(year, month)\n","        # directorio local\n","        local_path = self.generate_local_path(year, month)\n","\n","        # registro de detalles de la descarga\n","        download_info = {\n","            \"year\": year,\n","            \"month\": month,\n","            \"url\": url,\n","            \"local_path\": local_path,\n","            \"success\": False,\n","            \"error\": None,\n","            \"size_mb\": 0,\n","            \"hash\": \"\",\n","            \"download_time_seconds\": 0\n","        }\n","\n","        # comprueba si el fichero existe en local y es v√°lido\n","        if self.file_exists_and_valid(local_path):\n","            # actualiza el registro\n","            download_info.update({\n","                \"success\": True,\n","                \"size_mb\": get_file_size_mb(local_path),\n","                \"hash\": generate_file_hash(local_path),\n","                \"skipped\": True\n","            })\n","            print(f\"‚úì Fichero existe: {year}-{month:02d} ({download_info['size_mb']:.1f} MB)\")\n","            # devuelve informaci√≥n de la descarga\n","            return download_info\n","\n","        ## descarga con reintentos\n","\n","        # intenta hasta 'max_retries' veces la descarga\n","        for attempt in range(self.config['max_retries']):\n","            try:\n","                print(f\"üì• Descargando {year}-{month:02d} (intento \",\n","                 f\"{attempt + 1}/{self.config['max_retries']})\")\n","\n","                # inicia descarga con timeout; lanza error si hay fallo\n","                start_time = datetime.now()\n","                response = requests.get(url, timeout=self.config['timeout_seconds'])\n","                response.raise_for_status()\n","\n","                # guarda el contenido en el archivo local\n","                with open(local_path, 'wb') as f:\n","                    f.write(response.content)\n","\n","                # calcula la duraci√≥n de la descarga\n","                end_time = datetime.now()\n","                download_time = (end_time - start_time).total_seconds()\n","\n","                # verifica la descarga\n","                if self.file_exists_and_valid(local_path):\n","                    # actualiza el registro\n","                    download_info.update({\n","                        \"success\": True,\n","                        \"size_mb\": get_file_size_mb(local_path),\n","                        \"hash\": generate_file_hash(local_path),\n","                        \"download_time_seconds\": download_time,\n","                        \"attempt\": attempt + 1\n","                    })\n","                    print(f\"‚úÖ Descargado: {year}-{month:02d} ({download_info['size_mb']:.1f} MB)\")\n","                    break\n","                else:\n","                    raise Exception(\"Archivo descargado inv√°lido\")\n","\n","            except Exception as e:\n","                # hay alg√∫n error\n","                download_info[\"error\"] = str(e)\n","                print(f\"‚ùå Error en intento {attempt + 1}: {e}\")\n","\n","                if attempt < self.config['max_retries'] - 1:\n","                    # si no es el √∫ltimo intento, espera 5 seg antes de reintentar\n","                    print(\"‚è≥ Reintentando en 5 segundos...\")\n","                    import time\n","                    time.sleep(5)\n","\n","        # devuelve la informaci√≥n de la descarga\n","        return download_info\n","\n","    def download_all(self) -> List[Dict]:\n","        \"\"\"\n","        Descarga todos los archivos definidos en la configuraci√≥n\n","\n","        Returns:\n","            List[Dict]: Lista de estad√≠sticas de descarga\n","        \"\"\"\n","        print(\"=== INICIANDO DESCARGA MASIVA ===\")\n","\n","        # recorre todos los meses a descargar\n","        for month_config in self.config['months_to_ingest']:\n","            # descarga el mes actual\n","            download_result = self.download_file(month_config['year'], month_config['month'])\n","            # guarda el resultado\n","            self.download_stats.append(download_result)\n","\n","            # log del evento\n","            log_ingestion_event(\"download\", download_result)\n","\n","        return self.download_stats"],"metadata":{"id":"OjG1uowdUf6E","executionInfo":{"status":"ok","timestamp":1762681071440,"user_tz":-60,"elapsed":33,"user":{"displayName":"Enrique Mej√≠a","userId":"14106173949036430943"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"xdbqzprWojRq","executionInfo":{"status":"ok","timestamp":1762681071460,"user_tz":-60,"elapsed":6,"user":{"displayName":"Enrique Mej√≠a","userId":"14106173949036430943"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["class DataSchemaValidator:\n","    \"\"\"\n","    Valida el esquema (estructura y tipos de columnas) de un Dataframe\n","    \"\"\"\n","\n","    def __init__(self):\n","        \"\"\"\n","        Esquema esperado para NYC Taxi data\n","        \"\"\"\n","        self.expected_schema = StructType([\n","            StructField(\"VendorID\", LongType(), True),\n","            StructField(\"tpep_pickup_datetime\", TimestampType(), True),\n","            StructField(\"tpep_dropoff_datetime\", TimestampType(), True),\n","            StructField(\"passenger_count\", DoubleType(), True),\n","            StructField(\"trip_distance\", DoubleType(), True),\n","            StructField(\"RatecodeID\", DoubleType(), True),\n","            StructField(\"store_and_fwd_flag\", StringType(), True),\n","            StructField(\"PULocationID\", LongType(), True),\n","            StructField(\"DOLocationID\", LongType(), True),\n","            StructField(\"payment_type\", LongType(), True),\n","            StructField(\"fare_amount\", DoubleType(), True),\n","            StructField(\"extra\", DoubleType(), True),\n","            StructField(\"mta_tax\", DoubleType(), True),\n","            StructField(\"tip_amount\", DoubleType(), True),\n","            StructField(\"tolls_amount\", DoubleType(), True),\n","            StructField(\"improvement_surcharge\", DoubleType(), True),\n","            StructField(\"total_amount\", DoubleType(), True),\n","            StructField(\"congestion_surcharge\", DoubleType(), True),\n","            StructField(\"airport_fee\", DoubleType(), True)\n","        ])\n","\n","    def validate_schema(self, df, file_info: Dict) -> Dict:\n","        \"\"\"\n","        Valida el esquema de un DataFrame\n","\n","        Args:\n","            df (DataFrame): DataFrame a validar\n","            file_info (Dict): Informaci√≥n del archivo (a√±o y mes)\n","\n","        Returns:\n","            Dict: Resultado de la validaci√≥n\n","        \"\"\"\n","        # inicializa resultados de la validaci√≥n\n","        validation_result = {\n","            \"file\": f\"{file_info['year']}-{file_info['month']:02d}\",\n","            \"schema_valid\": True,\n","            \"missing_columns\": [],\n","            \"extra_columns\": [],\n","            \"type_mismatches\": []\n","        }\n","\n","        # columnas del dataframe y columnas esperadas\n","        actual_columns = set(col.lower() for col in df.columns)\n","        expected_columns = set(field.name.lower() for field in self.expected_schema.fields)\n","\n","        # columnas faltantes\n","        validation_result[\"missing_columns\"] = list(expected_columns - actual_columns)\n","\n","        # columnas de m√°s\n","        validation_result[\"extra_columns\"] = list(actual_columns - expected_columns)\n","\n","        ## verifica los tipos de datos\n","\n","        # crea un mapeo nombre_columna_lowercase -> nombre_original\n","        colname_map = {col.lower(): col for col in df.columns}\n","\n","        # recorre las columnas esperadas\n","        for field in self.expected_schema.fields:\n","\n","            # comprueba que la columna exista en el dataframe\n","            field_lower = field.name.lower()\n","            if field_lower in colname_map:\n","\n","                # obtiene el tipo en el dataframe y en el esperado\n","                actual_col = colname_map[field_lower]\n","                actual_type = dict(df.dtypes)[actual_col]\n","                expected_type = str(field.dataType).lower()\n","\n","                # compara los tipos\n","                if not self._types_compatible(actual_type, expected_type):\n","                    validation_result[\"type_mismatches\"].append({\n","                        \"column\": field.name,\n","                        \"expected\": expected_type,\n","                        \"actual\": actual_type\n","                    })\n","\n","        # marca si el esquema del dataframe es v√°lido\n","        validation_result[\"schema_valid\"] = (\n","            len(validation_result[\"missing_columns\"]) == 0 and\n","            len(validation_result[\"type_mismatches\"]) == 0\n","        )\n","\n","        # devuelve el resultado de la validaci√≥n\n","        return validation_result\n","\n","    def _types_compatible(self, actual: str, expected: str) -> bool:\n","        \"\"\"\n","        Verifica si los tipos son compatibles\n","\n","        Args:\n","            actual (str): Tipo actual (del dataframe actual)\n","            expected (str): Tipo esperado\n","\n","        Returns:\n","            bool: True si son compatibles, False en caso contrario\n","        \"\"\"\n","        # mapeo de tipos de PySpark y otros comunes que puede tener el dataframe actual\n","        # biblioteca { tipo PySpark: tipos compatibles }\n","        '''\n","        IMPORTANTE: para estos datasets se mapea bigint con DoubleType porque\n","        columnas como passenger_count y RatecodeID pueden venir como entero aunque sean\n","        enteros peque√±os, y no habr√° problema en convertir en DoubleType m√°s adelante.\n","        '''\n","        type_mappings = {\n","            \"longtype\": [\"long\", \"bigint\", \"int\"],\n","            \"long\": [\"long\", \"bigint\", \"int\"],\n","            \"bigint\": [\"long\", \"bigint\", \"int\"],\n","            \"integer\": [\"long\", \"bigint\", \"int\"],\n","            \"double\": [\"double\", \"float\", \"long\", \"bigint\", \"int\"],\n","            \"doubletype\": [\"double\", \"float\", \"long\", \"bigint\", \"int\"],\n","            \"string\": [\"string\"],\n","            \"stringtype\": [\"string\"],\n","            \"timestamp\": [\"timestamp\", \"datetime\"],\n","            \"timestamptype\": [\"timestamp\", \"datetime\"]\n","        }\n","\n","        # convierte tipo del dataframe actual a min√∫sculas\n","        actual = actual.lower()\n","        # convierte tipo esperado a min√∫sculas\n","        expected = expected.lower()\n","\n","        # recorre el mapeo { tipo PySpark: tipos compatibles }\n","        for expected_base, compatible_types in type_mappings.items():\n","\n","            # comprueba si el tipo PySpark est√° contenido en el tipo esperado\n","            # ej: expected = \"bigint unsigned\", expected_base = \"bigint\"\n","            if expected_base in expected:\n","\n","                # comprueba si el tipo actual es compatible con alguno de los tipos esperados:\n","                # recorre la lista de tipos compatibles, devuelve True si el tipo actual\n","                # est√° contenido en los tipos compatibles\n","                return any(comp_type in actual for comp_type in compatible_types)\n","\n","        # si no se encontr√≥ ning√∫n tipo base en expected, comprueba si actual y expected son iguales\n","        return actual == expected"],"metadata":{"id":"Hoe9Yk-_8skt","executionInfo":{"status":"ok","timestamp":1762681071578,"user_tz":-60,"elapsed":103,"user":{"displayName":"Enrique Mej√≠a","userId":"14106173949036430943"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# v2\n","class DataContentValidator:\n","    \"\"\"\n","    Valida el contenido de un DataFrame de NYC Taxi comprobando valores nulos,\n","    datos inv√°lidos, outliers y coherencia temporal, devolviendo estad√≠sticas resumidas.\n","    \"\"\"\n","\n","    def __init__(self, max_distance: float = 500.0, max_passengers: int = 8):\n","        \"\"\"\n","        Inicializa el validador con par√°metros m√°ximos de distancia y n√∫mero de pasajeros\n","        \"\"\"\n","        self.max_distance = max_distance\n","        self.max_passengers = max_passengers\n","\n","    def _get_basic_quality_metrics(self, df: DataFrame, get_col_name) -> Dict[str, Any]:\n","        \"\"\"\n","        Calcula agregados de valores nulos y registros con datos inv√°lidos o extremos\n","\n","        Args:\n","            df (DataFrame): DataFrame a validar\n","            get_col_name (callable): Funci√≥n para obtener el nombre real de una columna\n","\n","        Returns:\n","            Dict[str, Any]: Diccionario con los resultados de la agregaci√≥n\n","        \"\"\"\n","\n","        # contador de nulos por columnas\n","        nulls = [\n","            F.sum(F.when(F.col(c).isNull(), 1).otherwise(0)).alias(f\"null_{c}\")\n","            for c in df.columns\n","        ]\n","\n","        # nombres reales de las columnas clave\n","        trip_distance_col = get_col_name(\"trip_distance\")\n","        fare_amount_col = get_col_name(\"fare_amount\")\n","        passenger_count_col = get_col_name(\"passenger_count\")\n","\n","        # contador de registros con valores inv√°lidos/extremos\n","        quality = [\n","            F.sum((F.col(trip_distance_col) <= 0).cast(\"int\")).alias(\"bad_dist\"),\n","            F.sum((F.col(fare_amount_col) <= 0).cast(\"int\")).alias(\"bad_fare\"),\n","            F.sum((\n","                (F.col(passenger_count_col) <= 0) | (F.col(passenger_count_col) > self.max_passengers)\n","                ).cast(\"int\")).alias(\"bad_pax\"),\n","            F.sum((F.col(trip_distance_col) > self.max_distance).cast(\"int\")).alias(\"extreme_dist\")\n","        ]\n","\n","        # ejecuta la agregaci√≥n\n","        row = df.select(*(nulls + quality)).first()\n","\n","        # devuelve resultado como diccionario\n","        return row.asDict()\n","\n","    def _get_null_percentages(self, stats: Dict[str, Any], cols: list, total: int) -> Dict[str, float]:\n","        \"\"\"\n","        Calcula el porcentaje de valores nulos por columna\n","\n","        Args:\n","            stats (Dict[str, Any]): Diccionario con los resultados de la agregaci√≥n\n","            cols (list): Lista de nombres de columna\n","            total (int): Total de registros\n","\n","        Returns:\n","            Dict[str, float]: Diccionario con los porcentajes\n","        \"\"\"\n","        return {\n","            col: round((stats.get(f\"null_{col}\", 0) or 0) / total * 100, 2)\n","            for col in cols\n","        }\n","\n","    def _get_data_quality_issues(self, stats: Dict[str, Any], total: int) -> Dict[str, float]:\n","        \"\"\"\n","        Calcula el porcentaje de registros con datos inv√°lidos\n","        - distancia\n","        - tarifa\n","        - n√∫mero de pasajeros\n","        - outliers\n","\n","        Args:\n","            stats (Dict[str, Any]): Diccionario con los resultados de la agregaci√≥n\n","            total (int): Total de registros\n","\n","        Returns:\n","            Dict[str, float]: Diccionario con los porcentajes\n","        \"\"\"\n","\n","        return {\n","            \"invalid_distance_pct\": round((stats.get(\"bad_dist\", 0) or 0) / total * 100, 2),\n","            \"invalid_fare_pct\": round((stats.get(\"bad_fare\", 0) or 0) / total * 100, 2),\n","            \"invalid_passengers_pct\": round((stats.get(\"bad_pax\", 0) or 0) / total * 100, 2),\n","            \"extreme_distance_pct\": round((stats.get(\"extreme_dist\", 0) or 0) / total * 100, 2)\n","        }\n","\n","    def _get_temporal_stats(self, df: DataFrame, get_col_name, total: int) -> Dict[str, Any]:\n","        \"\"\"\n","        Eval√∫a coherencia temporal entre pickup (inicio del viaje) y dropoff (final),\n","        y extrae fechas m√≠nimas y m√°ximas\n","\n","        Args:\n","            df (DataFrame): DataFrame a validar\n","            get_col_name (callable): Funci√≥n para obtener el nombre real de una columna\n","            total (int): Total de registros\n","\n","        Returns:\n","            Dict[str, Any]: Diccionario con los resultados de la agregaci√≥n\n","        \"\"\"\n","\n","        # nombres reales de las columnas clave\n","        pickup_col = get_col_name(\"tpep_pickup_datetime\")\n","        dropoff_col = get_col_name(\"tpep_dropoff_datetime\")\n","\n","        # comprueba si las columnas temporales existen\n","        if pickup_col is None or dropoff_col is None:\n","            # columnas temporales no existen\n","            print(f\"Advertencia: Columnas temporales no encontradas. pickup_col: {pickup_col}, \",\n","                  f\"dropoff_col: {dropoff_col}\")\n","            return {\n","                \"inverted_dates_pct\": 0.0,\n","                \"min_pickup\": \"N/A\",\n","                \"max_pickup\": \"N/A\",\n","                \"min_dropoff\": \"N/A\",\n","                \"max_dropoff\": \"N/A\"\n","            }\n","\n","        # columnas temporales s√≠ existen\n","        try:\n","            row = df.select(\n","                F.sum((F.col(dropoff_col) < F.col(pickup_col)).cast(\"int\")).alias(\"inverted_dates\"),\n","                F.min(F.col(pickup_col)).alias(\"min_pu\"),\n","                F.max(F.col(pickup_col)).alias(\"max_pu\"),\n","                F.min(F.col(dropoff_col)).alias(\"min_do\"),\n","                F.max(F.col(dropoff_col)).alias(\"max_do\")\n","            ).first()\n","\n","            return {\n","                \"inverted_dates_pct\": round((row[\"inverted_dates\"] or 0) / total * 100, 2),\n","                \"min_pickup\": str(row[\"min_pu\"]) if row[\"min_pu\"] else \"N/A\",\n","                \"max_pickup\": str(row[\"max_pu\"]) if row[\"max_pu\"] else \"N/A\",\n","                \"min_dropoff\": str(row[\"min_do\"]) if row[\"min_do\"] else \"N/A\",\n","                \"max_dropoff\": str(row[\"max_do\"]) if row[\"max_do\"] else \"N/A\"\n","            }\n","\n","        except Exception as e:\n","            print(f\"Error en agregaciones temporales: {e}\")\n","            return {\n","                \"inverted_dates\": 0,\n","                \"min_pickup\": \"N/A\",\n","                \"max_pickup\": \"N/A\",\n","                \"min_dropoff\": \"N/A\",\n","                \"max_dropoff\": \"N/A\"\n","            }\n","\n","    def validate_content(self, df: DataFrame, file_info: Dict[str, int]) -> Dict[str, Any]:\n","        \"\"\"\n","        Ejecuta todas las validaciones sobre el Dataframe y devuelve un resumen estructurado\n","\n","        Args:\n","            df (DataFrame): DataFrame a validar\n","            file_info (Dict): Informaci√≥n del archivo (a√±o y mes)\n","\n","        Returns:\n","            Dict: Resultado de la validaci√≥n\n","        \"\"\"\n","\n","        # inicializa el resultado\n","        result = {\n","            \"file\": f\"{file_info['year']}-{file_info['month']:02d}\",\n","            \"total_records\": 0,\n","            \"null_percentages\": {},\n","            \"data_quality_issues\": {},\n","            \"temporal_validation\": {}\n","        }\n","\n","        try:\n","            # contador de registros\n","            result[\"total_records\"] = df.count()\n","\n","            # comprueba que haya registros\n","            if result[\"total_records\"] == 0:\n","                result[\"status\"] = \"empty\"\n","                result[\"data_quality_issues\"][\"empty_dataset\"] = True\n","                return result\n","\n","            # mapeo de nombres de columnas ignorando may√∫sculas/min√∫sculas\n","            colname_map = {col.lower(): col for col in df.columns}\n","            def get_col_name(normalized_name: str) -> Optional[str]:\n","                return colname_map.get(normalized_name.lower())\n","\n","            ## agregaciones de calidad de datos\n","\n","            # identifica los nombres reales de las columnas clave\n","            required = [\"trip_distance\", \"fare_amount\", \"passenger_count\"]\n","            missing = [col for col in required if get_col_name(col) is None]\n","            if missing:\n","                result[\"status\"] = \"error\"\n","                result[\"error\"] = f\"Faltan columnas requeridas: {missing}\"\n","                return result\n","\n","            basic_stats = self._get_basic_quality_metrics(df, get_col_name)\n","            result[\"null_percentages\"] = self._get_null_percentages(\n","                basic_stats, df.columns, result[\"total_records\"]\n","            )\n","            result[\"data_quality_issues\"] = self._get_data_quality_issues(\n","                basic_stats, result[\"total_records\"]\n","            )\n","\n","            temporal_stats = self._get_temporal_stats(df, get_col_name, result[\"total_records\"])\n","            result[\"temporal_validation\"] = temporal_stats\n","\n","        except Exception as e:\n","            result[\"validation_error\"] = str(e)\n","            print(f\"Error en validaci√≥n: {e}\")\n","\n","        return result"],"metadata":{"id":"wQT-YcHP8set","executionInfo":{"status":"ok","timestamp":1762681071693,"user_tz":-60,"elapsed":79,"user":{"displayName":"Enrique Mej√≠a","userId":"14106173949036430943"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"8ImFIK8e8rxZ","executionInfo":{"status":"ok","timestamp":1762681071746,"user_tz":-60,"elapsed":30,"user":{"displayName":"Enrique Mej√≠a","userId":"14106173949036430943"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["**Ingesta de Datos**"],"metadata":{"id":"YyV4GLW9883p"}},{"cell_type":"code","source":["# configuraci√≥n de la ingesta de datos\n","\n","'''\n","Datos de NYC Taxi desde la fuente oficial\n","months_to_ingest: lista de diccionarios, cada uno con el a√±o y mes que se quieren ingerir\n","M√°ximo 3 reintentos\n","Tiempo m√°ximo de espera de 5 minutos (300 seg.)\n","'''\n","\n","INGESTION_CONFIG = {\n","    \"base_url\": \"https://d37ci6vzurychx.cloudfront.net/trip-data\",\n","    \"data_type\": \"yellow_tripdata\",\n","    \"file_format\": \"parquet\",\n","    \"months_to_ingest\": [\n","        {\"year\": 2023, \"month\": 1},\n","        {\"year\": 2023, \"month\": 2},\n","        {\"year\": 2023, \"month\": 3}\n","    ],\n","    \"max_retries\": 3,\n","    \"timeout_seconds\": 300\n","}\n","\n","print(\"=== CONFIGURACI√ìN DE INGESTA ===\")\n","print(f\"Proyecto: {PROJECT_ROOT}\")\n","print(f\"Meses a ingestar: {len(INGESTION_CONFIG['months_to_ingest'])}\")\n","for month_config in INGESTION_CONFIG['months_to_ingest']:\n","    print(f\"  - {month_config['year']}-{month_config['month']:02d}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sYhryIUDrodk","executionInfo":{"status":"ok","timestamp":1762681071801,"user_tz":-60,"elapsed":49,"user":{"displayName":"Enrique Mej√≠a","userId":"14106173949036430943"}},"outputId":"57e3605d-01e1-4353-d43d-c0cad1e39fd6"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["=== CONFIGURACI√ìN DE INGESTA ===\n","Proyecto: /content/drive/MyDrive/taxi_project\n","Meses a ingestar: 3\n","  - 2023-01\n","  - 2023-02\n","  - 2023-03\n"]}]},{"cell_type":"code","source":["# crea una instancia del gestor de descargas\n","download_manager = NYCTaxiDownloadManager(INGESTION_CONFIG)"],"metadata":{"id":"Sula9nkMroR8","executionInfo":{"status":"ok","timestamp":1762681071803,"user_tz":-60,"elapsed":1,"user":{"displayName":"Enrique Mej√≠a","userId":"14106173949036430943"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# descarga todos los archivos definidos en la configuraci√≥n de la ingesta\n","download_results = download_manager.download_all()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Teu3NdLroHX","executionInfo":{"status":"ok","timestamp":1762681077474,"user_tz":-60,"elapsed":5670,"user":{"displayName":"Enrique Mej√≠a","userId":"14106173949036430943"}},"outputId":"fc5c5dd6-5988-42f0-8667-73c1df70cae8"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["=== INICIANDO DESCARGA MASIVA ===\n","‚úì Fichero existe: 2023-01 (45.5 MB)\n","üì• Descargando 2023-02 (intento  1/3)\n","‚úÖ Descargado: 2023-02 (45.5 MB)\n","üì• Descargando 2023-03 (intento  1/3)\n","‚úÖ Descargado: 2023-03 (53.5 MB)\n"]}]},{"cell_type":"code","source":["# descargas correctas\n","successful_downloads = [r for r in download_results if r['success']]\n","\n","print(f\"‚úÖ Descargas correctas: {len(successful_downloads)}\")\n","if successful_downloads:\n","\n","    # suma el tama√±o en MB de los archivos descargados correctamente\n","    total_size = sum(r['size_mb'] for r in successful_downloads)\n","    print(f\"üìä Tama√±o total correctas: {total_size:.1f} MB\")\n","\n","print()\n","\n","# descargas fallidas\n","failed_downloads = [r for r in download_results if not r['success']]\n","\n","print(f\"‚ùå Descargas fallidas: {len(failed_downloads)}\")\n","if failed_downloads:\n","    # muestra informaci√≥n de los archivos fallidos\n","    for failed in failed_downloads:\n","        print(f\"  - {failed['year']}-{failed['month']:02d}: {failed['error']}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JokNxB6AsMid","executionInfo":{"status":"ok","timestamp":1762681077627,"user_tz":-60,"elapsed":82,"user":{"displayName":"Enrique Mej√≠a","userId":"14106173949036430943"}},"outputId":"3567ed08-b75a-4651-9004-b9772b1fa70f"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Descargas correctas: 3\n","üìä Tama√±o total correctas: 144.5 MB\n","\n","‚ùå Descargas fallidas: 0\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"hVLqlVj-cYKI","executionInfo":{"status":"ok","timestamp":1762681077638,"user_tz":-60,"elapsed":8,"user":{"displayName":"Enrique Mej√≠a","userId":"14106173949036430943"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# valida los archivos descargados\n","print(\"=== VALIDANDO ARCHIVOS DESCARGADOS ===\")\n","\n","# crea instancia de clase de validaci√≥n de esquema\n","schema_validator = DataSchemaValidator()\n","\n","# crea instancia de clase de validaci√≥n de datos\n","MAX_DISTANCE = 300\n","MAX_PASSENGERS = 8\n","content_validator = DataContentValidator(max_distance=MAX_DISTANCE, max_passengers=MAX_PASSENGERS)\n","\n","# inicializa la lista de resultados\n","validation_results = []\n","\n","# recorre los archivos descargados correctamente\n","for download_result in successful_downloads:\n","\n","    print(f\"\\nüîç Validando {download_result['year']}-{download_result['month']:02d}...\")\n","\n","    try:\n","        # carga el archivo en un Dataframe de Spark\n","        ds = spark.read.parquet(download_result['local_path'])\n","\n","        # valida el esquema\n","        schema_validation = schema_validator.validate_schema(ds, download_result)\n","\n","        # valida el contenido\n","        content_validation = content_validator.validate_content(ds, download_result)\n","\n","        # combina ambos resultados\n","        combined_validation = {\n","            **download_result,\n","            \"schema_validation\": schema_validation,\n","            \"content_validation\": content_validation\n","        }\n","\n","        # agrega el resultado combinado a la lista de resultados\n","        validation_results.append(combined_validation)\n","\n","        # guarda el log de la validaci√≥n\n","        log_ingestion_event(\"validation\", combined_validation)\n","\n","        print(f\"  üìä  Registros: {content_validation['total_records']:,}\")\n","\n","        # muestra un resumen de la validaci√≥n\n","        if schema_validation[\"schema_valid\"]:\n","            print(f\"  ‚úÖ  Esquema v√°lido\")\n","        else:\n","            print(f\"  ‚ùå  Esquema no v√°lido\")\n","            display(schema_validation)\n","\n","        # muestra problemas de calidad de los datos\n","        quality_issues = content_validation.get('data_quality_issues', {})\n","        for issue, percentage in quality_issues.items():\n","\n","            # s√≥lo muestra los problemas de calidad si son > 0%\n","            MIN_PERCENTAGE = 0\n","\n","            if percentage > MIN_PERCENTAGE:\n","              print(f\"  ‚ö†Ô∏è  {issue}: {percentage}%\")\n","\n","    except Exception as e:\n","        # ha ocurrido alg√∫n error\n","        print(f\"  ‚ùå Error validando: {e}\")\n","        validation_results.append({\n","            **download_result,\n","            \"validation_error\": str(e)\n","        })"],"metadata":{"id":"iMkK_YuIUwHr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762681109793,"user_tz":-60,"elapsed":32152,"user":{"displayName":"Enrique Mej√≠a","userId":"14106173949036430943"}},"outputId":"de4ae16a-944e-4222-e0b3-3c63d807c6b1"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["=== VALIDANDO ARCHIVOS DESCARGADOS ===\n","\n","üîç Validando 2023-01...\n","  üìä  Registros: 3,066,766\n","  ‚úÖ  Esquema v√°lido\n","  ‚ö†Ô∏è  invalid_distance_pct: 1.5%\n","  ‚ö†Ô∏è  invalid_fare_pct: 0.85%\n","  ‚ö†Ô∏è  invalid_passengers_pct: 1.67%\n","\n","üîç Validando 2023-02...\n","  üìä  Registros: 2,913,955\n","  ‚úÖ  Esquema v√°lido\n","  ‚ö†Ô∏è  invalid_distance_pct: 1.41%\n","  ‚ö†Ô∏è  invalid_fare_pct: 0.89%\n","  ‚ö†Ô∏è  invalid_passengers_pct: 1.62%\n","\n","üîç Validando 2023-03...\n","  üìä  Registros: 3,403,766\n","  ‚úÖ  Esquema v√°lido\n","  ‚ö†Ô∏è  invalid_distance_pct: 1.43%\n","  ‚ö†Ô∏è  invalid_fare_pct: 0.91%\n","  ‚ö†Ô∏è  invalid_passengers_pct: 1.71%\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"ehzNiWLuIahq","executionInfo":{"status":"ok","timestamp":1762681109801,"user_tz":-60,"elapsed":4,"user":{"displayName":"Enrique Mej√≠a","userId":"14106173949036430943"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["**Bronze Layer**\n","\n","Transforma los archivos validados en una capa Bronze: capa persistente de datos en crudo con metadatos, guardados en Parket, particionados y preparados para etapas posteriores."],"metadata":{"id":"12y_TjBtM6XS"}},{"cell_type":"code","source":[],"metadata":{"id":"Kc-FXHeE7tLz","executionInfo":{"status":"ok","timestamp":1762681109808,"user_tz":-60,"elapsed":4,"user":{"displayName":"Enrique Mej√≠a","userId":"14106173949036430943"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# crea la capa Bronze\n","\n","print(\"=== CREANDO BRONZE LAYER ===\")\n","\n","# inicializa lista de resultados\n","bronze_datasets = []\n","\n","# recorre cada resultado de la validaci√≥n\n","for validation_result in validation_results:\n","\n","    # procesa s√≥lo los archivos descargados correctamente y con esquema v√°lido\n","    if (validation_result.get(\n","        'success', False\n","        ) and validation_result.get(\n","            'schema_validation', {}\n","        ).get('schema_valid', False)\n","        ):\n","\n","        # a√±o y mes del Dataset\n","        year = validation_result['year']\n","        month = validation_result['month']\n","\n","        print(f\"üì¶ Procesando {year}-{month:02d} para Bronze Layer...\")\n","\n","        try:\n","            # carga el archivo desde disco\n","            ds = spark.read.parquet(validation_result['local_path'])\n","\n","            # a√±ade los metadatos de ingesta\n","            ds_bronze = ds.withColumn(\"ingestion_timestamp\", current_timestamp()) \\\n","                         .withColumn(\"source_file\", lit(f\"{year}-{month:02d}\")) \\\n","                         .withColumn(\"ingestion_year\", lit(year)) \\\n","                         .withColumn(\"ingestion_month\", lit(month))\n","\n","            ## guarda el Dataframe\n","\n","            # append: a√±ade datos sin borrar lo anterior\n","            # particionado por a√±o y mes de ingesta\n","            # compresi√≥n snappy\n","            # formato parquet en la ruta indicada\n","            ds_bronze.write \\\n","                .mode(\"append\") \\\n","                .partitionBy(\"ingestion_year\", \"ingestion_month\") \\\n","                .option(\"compression\", \"snappy\") \\\n","                .parquet(BRONZE_PATH)\n","\n","            # a√±ade registro con informaci√≥n del dataset procesado\n","            bronze_datasets.append({\n","                \"year\": year,\n","                \"month\": month,\n","                \"records\": validation_result['content_validation']['total_records'],\n","                \"bronze_path\": BRONZE_PATH\n","            })\n","\n","            print(\"  ‚úÖ Guardado en Bronze: \",\n","             f\"{validation_result['content_validation']['total_records']:,} registros\")\n","\n","        except Exception as e:\n","            # ha ocurrido alg√∫n error\n","            print(f\"  ‚ùå Error guardando en Bronze: {e}\")\n","\n","    else:\n","      print(\"sin datos\")"],"metadata":{"id":"9GeVLW5qUzOJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762681185048,"user_tz":-60,"elapsed":75237,"user":{"displayName":"Enrique Mej√≠a","userId":"14106173949036430943"}},"outputId":"a4e3dbb6-4e77-451f-f47d-c2b3788d5cb8"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["=== CREANDO BRONZE LAYER ===\n","üì¶ Procesando 2023-01 para Bronze Layer...\n","  ‚úÖ Guardado en Bronze:  3,066,766 registros\n","üì¶ Procesando 2023-02 para Bronze Layer...\n","  ‚úÖ Guardado en Bronze:  2,913,955 registros\n","üì¶ Procesando 2023-03 para Bronze Layer...\n","  ‚úÖ Guardado en Bronze:  3,403,766 registros\n"]}]},{"cell_type":"code","source":["# verifica la capa Bronze y genera un archivo JSON con la informaci√≥n de ingesta\n","\n","print(\"=== VERIFICANDO BRONZE LAYER ===\")\n","\n","try:\n","    # carga los datos de la capteta de la capa Bronze\n","    bronze_df = spark.read.parquet(f\"{BRONZE_DIR}/taxi_data\")\n","    print(f\"‚úÖ Bronze Layer creado exitosamente\")\n","\n","\n","    # n√∫mero total de registros\n","    total_bronze_records = bronze_df.count()\n","    print(f\"üìä Total de registros en Bronze: {total_bronze_records:,}\")\n","\n","    # distribuci√≥n por a√±o y mes de ingesta con conteo de registros por cada partici√≥n\n","    month_distribution = bronze_df.groupBy(\"ingestion_year\", \"ingestion_month\") \\\n","                                 .count() \\\n","                                 .orderBy(\"ingestion_year\", \"ingestion_month\") \\\n","                                 .collect()\n","\n","    # muestra la distribuci√≥n por mes\n","    print(\"\\nüìÖ Distribuci√≥n por mes:\")\n","    for row in month_distribution:\n","        print(f\"  {row['ingestion_year']}-{row['ingestion_month']:02d}: {row['count']:,} registros\")\n","\n","    # crea diccionario de metadatos\n","    bronze_metadata = {\n","        \"creation_timestamp\": datetime.now().isoformat(),\n","        \"total_records\": total_bronze_records,\n","        \"datasets_included\": bronze_datasets,\n","        \"validation_summary\": {\n","            \"total_files_processed\": len(validation_results),\n","            \"successful_validations\": len([\n","                v for v in validation_results if v.get('schema_validation', {}).get('schema_valid', False)\n","                ]),\n","            \"total_size_mb\": sum(r['size_mb'] for r in successful_downloads)\n","        }\n","    }\n","\n","    # guarda los metadatos en un archivo JSON\n","    with open(f\"{METADATA_DIR}/bronze_layer_metadata.json\", \"w\") as f:\n","        json.dump(bronze_metadata, f, indent=2)\n","\n","    print(f\"\\nüíæ Metadatos guardados en: {METADATA_DIR}/bronze_layer_metadata.json\")\n","\n","except Exception as e:\n","    print(f\"‚ùå Error verificando Bronze Layer: {e}\")\n","\n","    # muestra detalles del error\n","    import traceback\n","    traceback.print_exc()"],"metadata":{"id":"BeyJ8BHdU2-7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762681188791,"user_tz":-60,"elapsed":3739,"user":{"displayName":"Enrique Mej√≠a","userId":"14106173949036430943"}},"outputId":"028694b5-de4b-4dc3-9895-a0aa7dfb375f"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["=== VERIFICANDO BRONZE LAYER ===\n","‚úÖ Bronze Layer creado exitosamente\n","üìä Total de registros en Bronze: 9,384,487\n","\n","üìÖ Distribuci√≥n por mes:\n","  2023-01: 3,066,766 registros\n","  2023-02: 2,913,955 registros\n","  2023-03: 3,403,766 registros\n","\n","üíæ Metadatos guardados en: /content/drive/MyDrive/taxi_project/metadata/bronze_layer_metadata.json\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"7yulv_7BBEWM","executionInfo":{"status":"ok","timestamp":1762681188807,"user_tz":-60,"elapsed":12,"user":{"displayName":"Enrique Mej√≠a","userId":"14106173949036430943"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# cierra Spark\n","spark.stop()\n","print(\"üîå Sesi√≥n Spark cerrada\")"],"metadata":{"id":"MGnHM2K1UhOc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762681189303,"user_tz":-60,"elapsed":493,"user":{"displayName":"Enrique Mej√≠a","userId":"14106173949036430943"}},"outputId":"2f1bfdc8-2e24-436f-dcc2-5159c0f6ceaf"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["üîå Sesi√≥n Spark cerrada\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"74GhUopyFhz1","executionInfo":{"status":"ok","timestamp":1762681189310,"user_tz":-60,"elapsed":4,"user":{"displayName":"Enrique Mej√≠a","userId":"14106173949036430943"}}},"execution_count":19,"outputs":[]}]}